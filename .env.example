# Rails Upgrade Agent - Environment Configuration Template
# Copy this file to .env and fill in your actual values

# =============================================================================
# AI/LLM Configuration - Local LLM Only
# =============================================================================

# =============================================================================
# Local LLM Configuration
# =============================================================================

# Default Local Model (Optional - will use DeepSeek if not specified)
# Options: 
#   - deepseek-ai/deepseek-coder-6.7b-instruct (Recommended)
#   - bigcode/starcoder2-7b
#   - codellama/CodeLlama-7b-Instruct-hf
LOCAL_LLM_MODEL=deepseek-ai/deepseek-coder-6.7b-instruct

# CUDA Configuration (Optional)
# Set to empty string to force CPU mode: CUDA_VISIBLE_DEVICES=""
# CUDA_VISIBLE_DEVICES=0

# HuggingFace Configuration (Optional)
# Disable symlink warnings on Windows
# HF_HUB_DISABLE_SYMLINKS_WARNING=1

# =============================================================================
# Application Configuration
# =============================================================================

# Default mode for CLI (Optional)
# Options: api, local
DEFAULT_LLM_MODE=api

# Maximum search results for context (Optional)
MAX_SEARCH_RESULTS=10

# Output directory for generated files (Optional)
OUTPUT_DIR=./output

# =============================================================================
# Development Configuration
# =============================================================================

# Debug mode (Optional)
DEBUG=false

# Log level (Optional)
# Options: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Cache directory (Optional)
CACHE_DIR=./.cache

# =============================================================================
# Performance Tuning
# =============================================================================

# GPU Memory fraction (Optional, 0.0-1.0)
GPU_MEMORY_FRACTION=0.8

# Batch size for processing (Optional)
BATCH_SIZE=1

# Maximum tokens for generation (Optional)
MAX_TOKENS=1024

# =============================================================================
# Security Configuration
# =============================================================================

# Allow local model downloads (Optional)
ALLOW_MODEL_DOWNLOAD=true

# Trust remote code (Optional - needed for some models)
TRUST_REMOTE_CODE=false

# =============================================================================
# Instructions
# =============================================================================
# 1. Copy this file: cp .env.example .env
# 2. Edit .env with your actual values (if using custom models)
# 3. Never commit .env to version control
# 4. Local LLM mode works without any API keys
# 5. All processing is done locally for privacy

# Optimized Knowledge Base Configuration
USE_OPTIMIZED_DATA=true
OPTIMIZED_INDEX_PATH=./data/optimized_faiss.index
OPTIMIZED_META_PATH=./data/optimized_meta.jsonl
DATA_QUALITY_VERSION=2.0

# Data Quality Metrics
KNOWLEDGE_BASE_SIZE_MB=3.2
TOTAL_CHUNKS=17951
DUPLICATE_ELIMINATION=true
